---
title: "Data Simulation"
author: "Tyler Wiederich"
format: html
---

```{r}
#| warning: false
#| message: false

library(tidyverse)
set.seed(2026)
theme_set(theme_bw())
```

# Stimuli Creation

A well established design in psychophysics experiments involving comparisons is the the method of constant stimuli. This design has the benefit that one value remains constant and the value varies. In some studies, the constant value can vary.

In this study, all values in the heatmap are between 0 and 100. The constant stimuli is set at 50 and the varying stimuli are created such that ratios are equally spaced between 50 and 90. The same ratios are used to create the stimuli smaller than 50 by using 50 as the denominator.

The method of constant stimuli is a common experimental design in psychophysics. In this design, two values are compared by asking participants to make a judgement. Some studies create an additional factor by varying the magnitude of the constant stimuli.

In our study, we restrict all values in the heatmap between 0 and 100. The constant stimuli is set at 50 and the varying stimuli is created such that

```{r}
#Parameters
constant <- 50
max_val <- 90
l <- 5

#Ratios
ratios <- seq(constant/max_val, 1, l = l)

#Values
lower <- constant*ratios
upper <- rev(constant/ratios)
values <- unique(c(lower, upper))

#Stimuli
stimuli <- expand_grid(values, constant) %>% 
  mutate(pair_id = row_number())
```

# Idea

1)  generate response surface as a mixture distribution of desired shape and uniform
2)  input one of the known values to a spot that is similar to its value
3)  look at all coordinates around the location and input the other value
4)  remove both coordinates from mixture distribution
5)  repeat until all values are used
6)  check that chosen coordinates are are not concentrated across x and y via two chi square tests
    -   if either are significant, re-simulate values

# Data Generation

Values for the heatmap are created with a mixture distribution / weighted average. With mixing parameter $c$, random variable $U$, and a function between 0 and 100 $g(X,Y)$, values are created as follows:

$$
f(X,Y)=c\cdot U_{[0,100]}+(1-c)\cdot g(X,Y)\qquad 0\leq c\leq 1;X,Y=1,\dots,10
$$

1.  INPUT x, y coordinates, mixing parameter, bivariate function, stimuli data frame, and iterations of datasets to simulate

2.  CREATE list to save each iteration

3.  FOR each iteration

    1.  CREATE grid $M$ with $(X,Y)$

    2.  INSERT $\{U,g(X,Y),f(X,Y)\}$ into $M$

    3.  CREATE empty dataset $D$

    4.  FOR each row of stimuli dataset with pairs $(S_1,S_2)$

        1.  CREATE dataset $D_1$ with differences between $f(X,Y)$ and $(S_1)$

            1.  FILTER $D_1$ with smallest differences

            2.  SAMPLE remaining rows to account for ties

        2.  CREATE dataset $D_2$ with differences between $f(X,Y)$ and $S_2$

            1.  FILTER $D_2$ for $(X,Y)$ with Manhattan distances of 3 or 4 from $(X,Y)$ of $D_1$

            2.  FILTER $D_2$ with smallest differences

            3.  SAMPLE remaining rows to account for ties

        3.  SAVE $D_1$ and $D_2$ into $D$

        4.  REMOVE $D$ from $M$

    5.  CREATE $M'$ by joining $D$ and $M$

    6.  CHECK that $(S_1,S_2)$ are approximately evenly spaced across $M'$

        1.  CALCULATE marginal counts of $(S_1,S_2)$ across $(X,Y)$

        2.  CALCULATE $\chi^2$ from a Chi-squared test across marginal counts of $X$ and $Y$

        3.  AVERAGE both $\chi^2$ statistics

            1.  *Remark*: the purpose of the Chi-squared tests is to make sure that the stimuli coordinates are not concentrated onto any particular part of the heatmap. The smaller the test statistic, the smaller the difference between marginal count of stimuli across $X$ or $Y$ and the expected counts. With 18 stimuli values, the expected count 1.8 per row/column

4.  EXTRACT dataset with smallest average chi-square statistic

5.  OUTPUT dataset

```{r}
generate_heatmap_data <- function(x=1:10, y=1:10, c=0.3, f, stimuli, num_iters = 20, ...){
  # x, y:     grid coordinates
  # c:        mixing parameter of true function and random noise
  # f:        function with arguments (x,y) to be used as the true surface 
  #             across the grid (need not be scaled)
  # stimuli:  data frame with three columns, where columns 1 and 2 are 
  #             values to compare and column 3 is the pair identifier
  # num_iters: number of iterations    
  # ...:      additional values to pass to f
  
  #Helper functions
  scale0to100 <- function(z){
  100*(z-min(z))/(max(z)-min(z))
  }
  
  save_iters <- list()
  for(i in 1:num_iters){
    #Create grid and calculate mixture distribution
    mixed_grid <- expand_grid(x,y) %>% 
    mutate(unif = runif(nrow(.), 0, 100),
           dtn = scale0to100(f(x,y)),
           f = c*unif + (1-c)*dtn)
    
    #Empty data frame to save results
    save_grid <- data.frame()
    
    #For each stimuli pair, place values into grid
    for(j in 1:nrow(stimuli)){
      val1 <- stimuli[j,1][[1]]; val2 <- stimuli[j,2][[1]]; pair_id <- stimuli[j,3][[1]]
      
      #Sample location of one value
      tmp1 <- mixed_grid %>% 
        mutate(z = val1, diff = abs(f-val1),
               pair_id) %>%
        # filter(diff <= 15) %>% 
        filter(diff == min(diff)) %>%
        slice_sample(n = 1) #to account for ties
    
      #Sample location of second value based off acceptable distances to first value
      tmp2 <- mixed_grid %>% 
        filter(((x == tmp1$x) & (y == tmp1$y)) | (abs(x-tmp1$x) + abs(y-tmp1$y)) %in% c(3,4)) %>% 
        anti_join(tmp1, by = c('x','y')) %>% 
        mutate(z = val2, diff = abs(f-val2),
               pair_id) %>% 
        filter(diff == min(diff)) %>% 
        slice_sample(n = 1) #to account for ties
      
      #Save locations and values of stimuli pair, remove from available spots
      save_grid <- bind_rows(save_grid, tmp1, tmp2)
      mixed_grid <- mixed_grid %>% 
        anti_join(save_grid, by = c('x', 'y'))
      
    }#end inner for loop
    
    #Join the used and unused coordinates, replacing 
    full_grid <- mixed_grid %>% 
      full_join(save_grid, by = c('x', 'y', 'unif', 'dtn', 'f')) %>% 
      mutate(z = ifelse(is.na(z), f, z))
    
    #Check that placed values are not congregated along x or y axis using chi square tests
    x_coord_check <- full_grid %>% 
      group_by(x) %>% 
      summarize(Count = sum(!is.na(pair_id)))
    tmp_x <- chisq.test(x_coord_check$Count, simulate.p.value = T)
    y_coord_check <- full_grid %>% 
      group_by(y) %>% 
      summarise(Count = sum(!is.na(pair_id)))
    tmp_y <- chisq.test(y_coord_check$Count, simulate.p.value = T)
    
    #Save iterations into list
    save_iters[[i]] <- list(data = full_grid, chisq = mean(c(tmp_x$statistic, tmp_y$statistic)))

  }#end outer for loop
  
  #Find iteration with smallest average chi square statistic
  chisq <- numeric(length(save_iters))
  for(i in 1:length(chisq)){
    chisq[i] <- save_iters[[i]][['chisq']]
  }
  best_fit <- save_iters[[which.min(chisq)]][['data']]
  return(best_fit)
}
```

# Examples

```{r}
#| fig-cap: "Semisphere"
dat = generate_heatmap_data(f = \(x,y)(36-(x-mean(x))^2-(y-mean(y))^2), stimuli = stimuli, num_iters = 10, c = 0.25, x = 1:10, y = 1:10)

# p <- ggplot(dat, aes(x, y, fill = z)) + 
#   geom_tile() + 
#   geom_text(aes(label = pair_id)) + 
#   # scale_fill_gradient(low = 'white', high = 'darkblue') +
#   scale_fill_viridis_c(limits = c(0, 100)) +
#   theme(aspect.ratio = 1)
# p



```

```{r}
#| fig-cap: "Saddle-point"
dat = generate_heatmap_data(f = \(x,y)(36-(x-mean(x))^2+(y-mean(y))^2), stimuli = stimuli, num_iters = 10, c = 0.25)
p <- ggplot(dat, aes(x, y, fill = z)) + 
  geom_tile() + 
  geom_text(aes(label = pair_id)) + 
  # scale_fill_gradient(low = 'white', high = 'darkblue') +
  scale_fill_viridis_c(limits = c(0, 100)) +
  theme(aspect.ratio = 1)
p
```

```{r}
#| fig-cap: "Increase in X"
dat = generate_heatmap_data(f = \(x,y)(x), stimuli = stimuli, num_iters = 20, c = 0.25)
p <- ggplot(dat, aes(x, y, fill = z)) + 
  geom_tile() + 
  geom_text(aes(label = pair_id)) + 
  scale_fill_gradient(low = 'white', high = 'darkblue') +
  theme(aspect.ratio = 1)
p
```

```{r}
#| fig-cap: "Increase in X and Y"
dat = generate_heatmap_data(f = \(x,y)(x+y), stimuli = stimuli, num_iters = 20, c = 0.25)
p <- ggplot(dat, aes(x, y, fill = z)) + 
  geom_tile() + 
  geom_text(aes(label = pair_id)) + 
  scale_fill_gradient(low = 'white', high = 'darkblue') +
  theme(aspect.ratio = 1)
p
```

```{r}
#| fig-cap: "Other Example"
dat = generate_heatmap_data(f = \(x,y)(sin(x^2+y^2)), stimuli = stimuli, 
                            num_iters = 10, c = 0.25, x = 1:100, y = 1:100)
p <- ggplot(dat, aes(x, y, fill = z)) + 
  geom_tile() + 
  geom_text(aes(label = pair_id)) + 
  scale_fill_gradient(low = 'white', high = 'darkblue') +
  theme(aspect.ratio = 1)
p
```

```{r}
#| fig-cap: "Other Example"
dat = generate_heatmap_data(f = \(x,y)(sin(x+y^2)), stimuli = stimuli, 
                            num_iters = 10, c = 0.25, x = 1:100, y = 1:100)
p <- ggplot(dat, aes(x, y, fill = z)) + 
  geom_tile() + 
  geom_text(aes(label = pair_id)) + 
  scale_fill_gradient(low = 'white', high = 'darkblue') +
  theme(aspect.ratio = 1)
p
```

```{r}
#| fig-cap: "Other Example"
dat = generate_heatmap_data(f = \(x,y)(sin(5*x)*cos(5*y)), stimuli = stimuli, 
                            num_iters = 10, c = 0.25, x = seq(1, 10, l = 100), y = seq(1, 10, l = 100))
p <- ggplot(dat, aes(x, y, fill = z)) + 
  geom_tile() + 
  geom_text(aes(label = pair_id)) + 
  scale_fill_gradient(low = 'white', high = 'darkblue') +
  theme(aspect.ratio = 1)
p
```



